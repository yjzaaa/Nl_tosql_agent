"""Excel åŠ è½½ä¸ç®¡ç†æ¨¡å— - æ”¯æŒå¤šè¡¨ç®¡ç†"""

import uuid, json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import pandas as pd

from src.config.settings import get_config
from src.core.data_sources import DataSourceStrategy, ExcelDataSource

# ============== å¤–éƒ¨é…ç½®ï¼šå­—æ®µåç™½åå• ==============
# åœ¨æ­¤é…ç½®éœ€è¦ä¿ç•™æ‰€æœ‰ç±»å‹å€¼çš„å­—æ®µåï¼Œå¯æ ¹æ®éœ€æ±‚éšæ—¶ä¿®æ”¹
FIELD_WHITELIST = [
    "CC",
]


# ===================================================
@dataclass
class TableInfo:
    """è¡¨çš„å…ƒä¿¡æ¯"""

    id: str
    filename: str
    file_path: str
    sheet_name: str
    total_rows: int
    total_columns: int
    loaded_at: datetime = field(default_factory=datetime.now)
    is_joined: bool = False  # æ˜¯å¦ä¸ºè¿æ¥è¡¨
    source_tables: List[str] = field(default_factory=list)  # æºè¡¨åç§°åˆ—è¡¨


class ExcelLoader:
    """Excel æ–‡ä»¶åŠ è½½å™¨"""

    def __init__(self):
        self._df: Optional[pd.DataFrame] = None
        self._file_path: Optional[str] = None
        self._sheet_name: Optional[str] = None
        self._all_sheets: List[str] = []
        self._strategy: Optional[DataSourceStrategy] = None

        # ä¸šåŠ¡é€»è¾‘ä¸Šä¸‹æ–‡
        self.business_logic_context: str = ""
        self.common_questions_context: str = ""

    @property
    def is_loaded(self) -> bool:
        """æ˜¯å¦å·²åŠ è½½æ–‡ä»¶"""
        return self._df is not None

    @property
    def dataframe(self) -> pd.DataFrame:
        """è·å– DataFrame"""
        if self._df is None:
            raise ValueError("æœªåŠ è½½ Excel æ–‡ä»¶")
        return self._df

    def load(
        self, source: Union[str, DataSourceStrategy], sheet_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŠ è½½æ•°æ®æº

        Args:
            source: æ–‡ä»¶è·¯å¾„(str) æˆ– æ•°æ®æºç­–ç•¥å¯¹è±¡(DataSourceStrategy)
            sheet_name: å·¥ä½œè¡¨åç§°ï¼ˆä»…å½“ source ä¸ºæ–‡ä»¶è·¯å¾„æ—¶ä½¿ç”¨ï¼‰

        Returns:
            æ–‡ä»¶ç»“æ„ä¿¡æ¯
        """
        if isinstance(source, str):
            # å…¼å®¹æ—§æ¥å£ï¼šsource æ˜¯æ–‡ä»¶è·¯å¾„
            self._strategy = ExcelDataSource(source, sheet_name)
        elif isinstance(source, DataSourceStrategy):
            self._strategy = source
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {type(source)}")

        try:
            # åŠ è½½æ•°æ®
            self._df = self._strategy.load_data()

            # åŠ è½½å…ƒæ•°æ®
            metadata = self._strategy.get_metadata()
            self._file_path = metadata.get("file_path", "unknown_source")
            self._sheet_name = metadata.get("sheet_name", "unknown_sheet")
            self._all_sheets = metadata.get("all_sheets", [])

            # åŠ è½½ä¸Šä¸‹æ–‡
            context = self._strategy.get_context()
            self.business_logic_context = context.get("business_logic", "")
            self.common_questions_context = context.get("common_questions", "")

            return self.get_structure()
        except Exception as e:
            # æ¸…ç†çŠ¶æ€
            self._df = None
            raise e

    def get_structure(self) -> Dict[str, Any]:
        """è·å– Excel ç»“æ„ä¿¡æ¯"""
        if self._df is None:
            raise ValueError("æœªåŠ è½½ Excel æ–‡ä»¶")

        config = get_config()

        # åˆ—ä¿¡æ¯
        columns_info = []
        for col in self._df.columns:
            col_data = self._df[col]
            dtype = str(col_data.dtype)
            non_null = col_data.count()
            null_count = col_data.isna().sum()

            columns_info.append(
                {
                    "name": str(col),
                    "dtype": dtype,
                    "non_null_count": int(non_null),
                    "null_count": int(null_count),
                }
            )

        return {
            "file_path": self._file_path,
            "sheet_name": self._sheet_name,
            "all_sheets": self._all_sheets,
            "total_rows": len(self._df),
            "total_columns": len(self._df.columns),
            "columns": columns_info,
        }

    def get_preview(self, n_rows: Optional[int] = None) -> Dict[str, Any]:
        """è·å–æ•°æ®é¢„è§ˆ

        Args:
            n_rows: é¢„è§ˆè¡Œæ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼

        Returns:
            é¢„è§ˆæ•°æ®
        """
        if self._df is None:
            raise ValueError("æœªåŠ è½½ Excel æ–‡ä»¶")

        config = get_config()
        if n_rows is None:
            n_rows = config.excel.max_preview_rows

        preview_df = self._df.head(n_rows)

        return {
            "columns": list(self._df.columns),
            "data": preview_df.to_dict(orient="records"),
            "preview_rows": len(preview_df),
            "total_rows": len(self._df),
        }

    def get_summary(self) -> str:
        """è·å– Excel æ‘˜è¦ä¿¡æ¯ï¼ˆç”¨äº Agent ä¸Šä¸‹æ–‡ï¼‰"""
        if self._df is None:
            return "æœªåŠ è½½ Excel æ–‡ä»¶"

        structure = self.get_structure()
        preview = self.get_preview()

        lines = [
            f"ğŸ“Š **å·²åŠ è½½ Excel æ–‡ä»¶**: {structure['file_path']}",
            f"ğŸ“‹ **å½“å‰å·¥ä½œè¡¨**: {structure['sheet_name']}",
            f"ğŸ“‘ **æ‰€æœ‰å·¥ä½œè¡¨**: {', '.join(structure['all_sheets'])}",
            f"ğŸ“ **æ•°æ®è§„æ¨¡**: {structure['total_rows']} è¡Œ Ã— {structure['total_columns']} åˆ—",
            "",
            "**åˆ—ä¿¡æ¯**:",
        ]

        for col in structure["columns"]:
            lines.append(
                f"  - `{col['name']}` ({col['dtype']}): {col['non_null_count']} éç©ºå€¼"
            )

        lines.append("")
        lines.append(f"**å‰ {preview['preview_rows']} è¡Œæ•°æ®é¢„è§ˆ**:")

        # ç®€å•è¡¨æ ¼æ ¼å¼
        if preview["data"]:
            headers = preview["columns"]
            lines.append("| " + " | ".join(str(h) for h in headers) + " |")
            lines.append("| " + " | ".join("---" for _ in headers) + " |")
            for row in preview["data"]:
                values = [str(row.get(h, ""))[:20] for h in headers]  # æˆªæ–­é•¿å€¼
                lines.append("| " + " | ".join(values) + " |")

        # è¿½åŠ ä¸šåŠ¡ä¸Šä¸‹æ–‡
        if self.business_logic_context:
            lines.append("")
            lines.append("## ğŸ“š ä¸šåŠ¡è§£é‡Šå’Œé€»è¾‘")
            lines.append(self.business_logic_context)

        if self.common_questions_context:
            lines.append("")
            lines.append("## â“ å¸¸è§é—®é¢˜å‚è€ƒ")
            lines.append(self.common_questions_context)

        return "\n".join(lines)


class MultiExcelLoader:
    """å¤šè¡¨ç®¡ç†å™¨ - ç®¡ç†å¤šä¸ª ExcelLoader å®ä¾‹"""

    def __init__(self):
        self._tables: Dict[str, ExcelLoader] = {}  # table_id -> ExcelLoader
        self._table_infos: Dict[str, TableInfo] = {}  # table_id -> TableInfo
        self._active_table_id: Optional[str] = None

    @property
    def is_loaded(self) -> bool:
        """æ˜¯å¦æœ‰ä»»ä½•è¡¨å·²åŠ è½½"""
        return len(self._tables) > 0

    @property
    def active_table_id(self) -> Optional[str]:
        """è·å–å½“å‰æ´»è·ƒè¡¨ID"""
        return self._active_table_id

    def add_table(
        self, file_path: str, sheet_name: Optional[str] = None
    ) -> tuple[str, Dict[str, Any]]:
        """æ·»åŠ ä¸€å¼ æ–°è¡¨ (å…¼å®¹æ—§æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨ ExcelDataSource ç­–ç•¥)

        Args:
            file_path: Excel æ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°

        Returns:
            (è¡¨ID, ç»“æ„ä¿¡æ¯)
        """
        return self.add_data_source(ExcelDataSource(file_path, sheet_name))

    def add_data_source(
        self, strategy: DataSourceStrategy
    ) -> tuple[str, Dict[str, Any]]:
        """æ·»åŠ ä¸€ä¸ªæ•°æ®æºç­–ç•¥

        Args:
            strategy: æ•°æ®æºç­–ç•¥å®ä¾‹

        Returns:
            (è¡¨ID, ç»“æ„ä¿¡æ¯)
        """
        # åˆ›å»ºæ–°çš„åŠ è½½å™¨å¹¶åŠ è½½æ•°æ®
        loader = ExcelLoader()
        structure = loader.load(strategy)

        # ç”Ÿæˆå”¯ä¸€ID
        table_id = str(uuid.uuid4())[:8]

        # è·å–å…ƒæ•°æ®
        metadata = strategy.get_metadata()
        filename = metadata.get("filename", "unknown")

        # å­˜å‚¨è¡¨ä¿¡æ¯
        self._tables[table_id] = loader
        self._table_infos[table_id] = TableInfo(
            id=table_id,
            filename=filename,
            file_path=metadata.get("file_path", ""),
            sheet_name=metadata.get("sheet_name", ""),
            total_rows=structure["total_rows"],
            total_columns=structure["total_columns"],
        )

        # è‡ªåŠ¨è®¾ä¸ºæ´»è·ƒè¡¨
        self._active_table_id = table_id

        return table_id, structure

    def remove_table(self, table_id: str) -> bool:
        """åˆ é™¤æŒ‡å®šè¡¨

        Args:
            table_id: è¡¨ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if table_id not in self._tables:
            return False

        del self._tables[table_id]
        del self._table_infos[table_id]

        # å¦‚æœåˆ é™¤çš„æ˜¯æ´»è·ƒè¡¨ï¼Œåˆ‡æ¢åˆ°å¦ä¸€å¼ è¡¨æˆ–è®¾ä¸ºNone
        if self._active_table_id == table_id:
            if self._tables:
                self._active_table_id = next(iter(self._tables.keys()))
            else:
                self._active_table_id = None

        return True

    def get_table(self, table_id: str) -> Optional[ExcelLoader]:
        """è·å–æŒ‡å®šè¡¨çš„åŠ è½½å™¨"""
        return self._tables.get(table_id)

    def get_table_info(self, table_id: str) -> Optional[TableInfo]:
        """è·å–æŒ‡å®šè¡¨çš„å…ƒä¿¡æ¯"""
        return self._table_infos.get(table_id)

    def get_active_loader(self) -> Optional[ExcelLoader]:
        """è·å–å½“å‰æ´»è·ƒè¡¨çš„åŠ è½½å™¨"""
        if self._active_table_id:
            return self._tables.get(self._active_table_id)
        return None

    def get_active_table_info(self) -> Optional[TableInfo]:
        """è·å–å½“å‰æ´»è·ƒè¡¨çš„å…ƒä¿¡æ¯"""
        if self._active_table_id:
            return self._table_infos.get(self._active_table_id)
        return None

    def set_active_table(self, table_id: str) -> bool:
        """è®¾ç½®å½“å‰æ´»è·ƒè¡¨

        Args:
            table_id: è¡¨ID

        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if table_id not in self._tables:
            return False
        self._active_table_id = table_id
        return True

    def list_tables(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰è¡¨çš„ä¿¡æ¯åˆ—è¡¨"""
        result = []
        for table_id, info in self._table_infos.items():
            result.append(
                {
                    "id": info.id,
                    "filename": info.filename,
                    "sheet_name": info.sheet_name,
                    "total_rows": info.total_rows,
                    "total_columns": info.total_columns,
                    "loaded_at": info.loaded_at.isoformat(),
                    "is_active": table_id == self._active_table_id,
                    "is_joined": info.is_joined,
                    "source_tables": info.source_tables,
                }
            )
        return result

    def get_table_columns(self, table_id: str) -> List[str]:
        """è·å–æŒ‡å®šè¡¨çš„åˆ—ååˆ—è¡¨"""
        loader = self.get_table(table_id)
        if loader and loader.is_loaded:
            return list(loader.dataframe.columns)
        return []

    def join_tables(
        self,
        table1_id: str,
        table2_id: str,
        keys1: List[str],
        keys2: List[str],
        join_type: str = "inner",
        new_name: str = "è¿æ¥è¡¨",
    ) -> tuple[str, Dict[str, Any]]:
        """è¿æ¥ä¸¤å¼ è¡¨ï¼ˆæ”¯æŒå¤šå­—æ®µè¿æ¥ï¼‰

        Args:
            table1_id: è¡¨1 ID
            table2_id: è¡¨2 ID
            keys1: è¡¨1 è¿æ¥å­—æ®µåˆ—è¡¨
            keys2: è¡¨2 è¿æ¥å­—æ®µåˆ—è¡¨
            join_type: è¿æ¥ç±»å‹ (inner/left/right/outer)
            new_name: æ–°è¡¨åç§°

        Returns:
            (æ–°è¡¨ID, ç»“æ„ä¿¡æ¯)
        """
        # éªŒè¯è¡¨å­˜åœ¨
        loader1 = self.get_table(table1_id)
        loader2 = self.get_table(table2_id)
        if not loader1 or not loader2:
            raise ValueError("æŒ‡å®šçš„è¡¨ä¸å­˜åœ¨")

        info1 = self.get_table_info(table1_id)
        info2 = self.get_table_info(table2_id)

        df1 = loader1.dataframe
        df2 = loader2.dataframe

        # éªŒè¯å­—æ®µæ•°é‡ä¸€è‡´
        if len(keys1) != len(keys2):
            raise ValueError("ä¸¤è¡¨çš„è¿æ¥å­—æ®µæ•°é‡å¿…é¡»ä¸€è‡´")

        if len(keys1) == 0:
            raise ValueError("è‡³å°‘éœ€è¦æŒ‡å®šä¸€ä¸ªè¿æ¥å­—æ®µ")

        # éªŒè¯å­—æ®µå­˜åœ¨
        for key in keys1:
            if key not in df1.columns:
                raise ValueError(f"è¡¨1ä¸­ä¸å­˜åœ¨å­—æ®µ: {key}")
        for key in keys2:
            if key not in df2.columns:
                raise ValueError(f"è¡¨2ä¸­ä¸å­˜åœ¨å­—æ®µ: {key}")

        # éªŒè¯è¿æ¥ç±»å‹
        valid_join_types = ["inner", "left", "right", "outer"]
        if join_type not in valid_join_types:
            raise ValueError(f"ä¸æ”¯æŒçš„è¿æ¥ç±»å‹: {join_type}ï¼Œå¯é€‰: {valid_join_types}")

        # æ‰§è¡Œè¿æ¥
        merged_df = pd.merge(
            df1,
            df2,
            left_on=keys1,
            right_on=keys2,
            how=join_type,
            suffixes=("_è¡¨1", "_è¡¨2"),
        )

        # åˆ›å»ºæ–°çš„åŠ è½½å™¨
        new_loader = ExcelLoader()
        new_loader._df = merged_df
        new_loader._file_path = f"[è¿æ¥è¡¨] {new_name}"
        new_loader._sheet_name = "merged"
        new_loader._all_sheets = ["merged"]

        # ç”Ÿæˆå”¯ä¸€ID
        table_id = str(uuid.uuid4())[:8]

        # å­˜å‚¨è¡¨ä¿¡æ¯
        self._tables[table_id] = new_loader
        self._table_infos[table_id] = TableInfo(
            id=table_id,
            filename=f"ğŸ”— {new_name}",
            file_path=f"[è¿æ¥è¡¨] {new_name}",
            sheet_name="merged",
            total_rows=len(merged_df),
            total_columns=len(merged_df.columns),
            is_joined=True,
            source_tables=[info1.filename, info2.filename],
        )

        # è‡ªåŠ¨è®¾ä¸ºæ´»è·ƒè¡¨
        self._active_table_id = table_id

        return table_id, new_loader.get_structure()

    def get_loaded_dataframes(self) -> Dict[str, pd.DataFrame]:
        """è·å–æ‰€æœ‰å·²åŠ è½½çš„ DataFrameï¼Œé”®ä¸ºæ–‡ä»¶åï¼ˆæ— åç¼€ï¼Œå·²æ¸…æ´—ï¼‰"""
        dataframes = {}
        for table_id, loader in self._tables.items():
            if not loader.is_loaded:
                continue

            info = self._table_infos.get(table_id)
            if not info:
                continue

            # ä¼˜å…ˆä½¿ç”¨å·¥ä½œè¡¨åç§°ä½œä¸ºå˜é‡åï¼Œå› ä¸ºåŒä¸€ä¸ªæ–‡ä»¶å¯èƒ½åŠ è½½å¤šä¸ª Sheet
            # å¦‚æœæ–‡ä»¶åä¸åŒä½† Sheet åç›¸åŒï¼Œåç»­åŠ è½½çš„ä¼šè¦†ç›–å‰é¢çš„ï¼ˆæš‚æ—¶æ¥å—è¿™ç§é™åˆ¶ï¼Œæˆ–è€…åç»­ä¼˜åŒ–ï¼‰
            raw_name = info.sheet_name

            # å¦‚æœ Sheet åæ˜¯é»˜è®¤çš„ "Sheet1" ç­‰ï¼Œæˆ–è€…ä¸ºäº†é˜²æ­¢å†²çªï¼Œå¯ä»¥è€ƒè™‘ç»„åˆæ–‡ä»¶å
            # ä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼ŒCostDataBase å’Œ Table7 æ˜¾ç„¶æ˜¯æ›´æœ‰æ„ä¹‰çš„åå­—

            # ç®€å•æ¸…æ´—ï¼šå°†éå­—æ¯æ•°å­—ä¸‹åˆ’çº¿çš„å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
            clean_name = raw_name.replace(" ", "_").replace("-", "_")

            # å¦‚æœå¼€å¤´æ˜¯æ•°å­—ï¼ŒåŠ å‰ç¼€
            if clean_name and clean_name[0].isdigit():
                clean_name = f"df_{clean_name}"

            dataframes[clean_name] = loader.dataframe

        return dataframes

    def get_active_summary(self) -> str:
        """è·å–å½“å‰æ´»è·ƒè¡¨çš„æ‘˜è¦"""
        loader = self.get_active_loader()
        if not loader:
            return "æœªåŠ è½½ Excel æ–‡ä»¶"

        summary = loader.get_summary()

        # è¿½åŠ å…¶ä»–å¯ç”¨è¡¨çš„ä¿¡æ¯
        loaded_dfs = self.get_loaded_dataframes()
        if len(loaded_dfs) > 1:
            summary += "\n\n## ğŸ“š å¯ç”¨æ•°æ®è¡¨ (å¯åœ¨ä»£ç ä¸­ç›´æ¥ä½¿ç”¨)\n"
            summary += "æ”¯æŒå¤šè¡¨æŸ¥è¯¢ï¼Œå·²ä¸ºæ‚¨æ³¨å…¥ä»¥ä¸‹ DataFrame å˜é‡ï¼ˆå˜é‡åæºè‡ª Sheet åç§°ï¼‰ï¼š\n"
            for var_name in loaded_dfs.keys():
                summary += f"- `{var_name}`\n"

        return summary

    def get_summary(self) -> str:
        """è·å–å½“å‰æ´»è·ƒè¡¨çš„æ‘˜è¦ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        return self.get_active_summary()

    @property
    def dataframe(self) -> pd.DataFrame:
        """è·å–å½“å‰æ´»è·ƒè¡¨çš„ DataFrameï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        loader = self.get_active_loader()
        if loader:
            return loader.dataframe
        raise ValueError("æœªåŠ è½½ Excel æ–‡ä»¶")

    # ===================== æ–°å¢æ ¸å¿ƒæ–¹æ³• =====================
    def get_all_tables_field_values_json(
        self,
        ensure_ascii: bool = False,
        indent: int = 4,
        keep_order: bool = True,
        field_whitelist: List[str] = None,  # å¯é€‰å‚æ•°ï¼Œæ”¯æŒè¿è¡Œæ—¶è¦†ç›–å¤–éƒ¨é…ç½®
    ) -> str:
        """
        è·å–å½“å‰å¯¹è±¡ä¸­æ‰€æœ‰è¡¨çš„ã€Œè¡¨-å­—æ®µ-å­—æ®µå€¼ã€å±‚çº§ç»“æ„çš„ JSON æ ¼å¼å­—ç¬¦ä¸²
        æ–°å¢ï¼š1. å­—ç¬¦ä¸²å­—æ®µå€¼å»é™¤é¦–å°¾ç©ºç™½ 2. å­—æ®µå€¼åˆ—è¡¨å»é‡ï¼ˆå¯é€‰ä¿ç•™é¦–æ¬¡å‡ºç°é¡ºåºï¼‰

        Args:
            ensure_ascii: æ˜¯å¦ç¡®ä¿ ASCII ç¼–ç ï¼ˆFalse æ”¯æŒä¸­æ–‡æ˜¾ç¤ºï¼‰
            indent: JSON æ ¼å¼åŒ–ç¼©è¿›ç©ºæ ¼æ•°
            keep_order: æ˜¯å¦ä¿ç•™å­—æ®µå€¼çš„é¦–æ¬¡å‡ºç°é¡ºåºï¼ˆTrue=ä¿ç•™ï¼ŒFalse=ä¸ä¿ç•™ï¼Œé«˜æ•ˆï¼‰

        Returns:
            ç»“æ„åŒ–çš„ JSON å­—ç¬¦ä¸²
        """
        # 1. æ„å»ºå±‚çº§åŒ–çš„ Python å­—å…¸ï¼ˆè¡¨->å­—æ®µ->å­—æ®µå€¼ï¼‰
        all_tables_data = {}
        # åˆå§‹åŒ–ç™½åå•ï¼šä¼˜å…ˆä½¿ç”¨æ–¹æ³•ä¼ å…¥å€¼ï¼Œæ— åˆ™ä½¿ç”¨å¤–éƒ¨å…¨å±€é…ç½®
        target_whitelist = field_whitelist or FIELD_WHITELIST

        for table_id, loader in self._tables.items():
            # è·³è¿‡æœªæˆåŠŸåŠ è½½æ•°æ®çš„è¡¨
            if not loader or not loader.is_loaded:
                continue

            # è·å–è¡¨çš„å…ƒä¿¡æ¯ï¼Œç”¨äºæ„å»ºè¡¨çš„æ ‡è¯†
            table_info = self.get_table_info(table_id)
            if not table_info:
                continue

            # è¡¨çš„å”¯ä¸€æ ‡è¯†ï¼ˆç»„åˆ IDã€æ–‡ä»¶åã€å·¥ä½œè¡¨åï¼Œæé«˜å¯è¯»æ€§ï¼‰
            table_identifier = f"{table_info.filename}ï¼ˆIDï¼š{table_id}ï¼ŒSheetï¼š{table_info.sheet_name}ï¼‰"

            # è·å–è¡¨çš„ DataFrame å¹¶è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆæ–¹ä¾¿æå–å­—æ®µå’Œå€¼ï¼‰
            df = loader.dataframe
            # å¤„ç† pandas ä¸­çš„ç‰¹æ®Šç±»å‹ï¼ˆNaTã€NaN ç­‰ï¼‰ï¼Œè½¬ä¸º JSON å¯åºåˆ—åŒ–æ ¼å¼
            df_clean = df.where(pd.notna(df), None)  # NaN/NaT æ›¿æ¢ä¸º None

            # æ„å»ºå­—æ®µ-å­—æ®µå€¼ç»“æ„ï¼šä»…ä¿ç•™å­—ç¬¦ä¸²ç±»å‹ï¼Œå»ç©ºç™½+å»é‡
            field_values = {}
            for column in df_clean.columns:
                # æå–è¯¥åˆ—æ‰€æœ‰å€¼
                column_values = df_clean[column].tolist()
                processed_values = []

                # æ­¥éª¤1ï¼šæ ¹æ®å­—æ®µæ˜¯å¦åœ¨ç™½åå•ï¼Œæ‰§è¡Œä¸åŒçš„ç­›é€‰/ä¿ç•™é€»è¾‘
                if column in target_whitelist:
                    # åˆ†æ”¯1ï¼šç™½åå•å­—æ®µ - ä¿ç•™æ‰€æœ‰ç±»å‹å€¼ï¼Œä»…å¯¹å­—ç¬¦ä¸²åšå»ç©ºç™½å¤„ç†
                    for val in column_values:
                        # å¯¹å­—ç¬¦ä¸²ç±»å‹ï¼šå»é¦–å°¾ç©ºç™½
                        if isinstance(val, str):
                            stripped_val = val.strip()
                            # ä¿ç•™å»ç©ºç™½åçš„å­—ç¬¦ä¸²ï¼ˆåŒ…æ‹¬ç©ºå­—ç¬¦ä¸²ï¼Œå¦‚éœ€è¿‡æ»¤å¯æ·»åŠ åˆ¤æ–­ï¼‰
                            processed_values.append(stripped_val)
                        # å¯¹æ—¶é—´ç±»å‹ï¼šæ ¼å¼åŒ–ä¸º ISO å­—ç¬¦ä¸²ï¼ˆä¿è¯ JSON å¯åºåˆ—åŒ–ï¼‰
                        elif isinstance(val, pd.Timestamp) or isinstance(val, datetime):
                            processed_values.append(val.isoformat())
                        # å…¶ä»–æ‰€æœ‰ç±»å‹ï¼šç›´æ¥ä¿ç•™ï¼ˆæ•°å­—ã€å¸ƒå°”ã€None ç­‰ï¼‰
                        else:
                            processed_values.append(val)
                else:
                    # åˆ†æ”¯2ï¼šéç™½åå•å­—æ®µ - ä»…ä¿ç•™å­—ç¬¦ä¸²ç±»å‹å€¼ï¼Œä¸”å»ç©ºç™½
                    for val in column_values:
                        if isinstance(val, str):
                            stripped_val = val.strip()
                            # å¯é€‰ï¼šè¿‡æ»¤å»ç©ºç™½åçš„ç©ºå­—ç¬¦ä¸²
                            if stripped_val:
                                processed_values.append(stripped_val)

                # æ­¥éª¤2ï¼šå¯¹å¤„ç†åçš„åˆ—è¡¨è¿›è¡Œå»é‡ï¼ˆå…¼å®¹æ‰€æœ‰ç±»å‹ï¼‰
                deduplicated_values = []
                if keep_order:
                    # ä¿ç•™é¦–æ¬¡å‡ºç°é¡ºåºçš„å»é‡ï¼ˆæ¨èï¼Œå…¼å®¹ä¸å¯å“ˆå¸Œç±»å‹ï¼‰
                    seen = set()
                    for val in processed_values:
                        # å¤„ç†ä¸å¯å“ˆå¸Œç±»å‹ï¼ˆå¦‚åˆ—è¡¨ï¼‰ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²åˆ¤æ–­å”¯ä¸€æ€§
                        try:
                            # å¯å“ˆå¸Œç±»å‹ç›´æ¥ä½¿ç”¨ï¼Œä¸å¯å“ˆå¸Œç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²
                            val_hashable = (
                                val
                                if isinstance(
                                    val, (int, float, str, bool, None.__class__)
                                )
                                else str(val)
                            )
                        except:
                            val_hashable = str(val)

                        if val_hashable not in seen:
                            seen.add(val_hashable)
                            deduplicated_values.append(val)
                else:
                    # é«˜æ•ˆå»é‡ï¼ˆä¸ä¿ç•™é¡ºåºï¼‰ï¼Œå…¼å®¹ä¸å¯å“ˆå¸Œç±»å‹é™çº§å¤„ç†
                    try:
                        deduplicated_values = list(set(processed_values))
                    except:
                        seen = set()
                        for val in processed_values:
                            val_hashable = str(val)
                            if val_hashable not in seen:
                                seen.add(val_hashable)
                                deduplicated_values.append(val)

                # å­˜å…¥æœ€ç»ˆå¤„ç†ç»“æœ
                field_values[column] = deduplicated_values

            # å°†å½“å‰è¡¨çš„æ•°æ®å­˜å…¥æ€»å­—å…¸
            all_tables_data[table_identifier] = {
                "table_meta": {
                    "table_id": table_id,
                    "filename": table_info.filename,
                    "sheet_name": table_info.sheet_name,
                    "total_rows": table_info.total_rows,
                    "total_columns": table_info.total_columns,
                    "is_active": table_id == self._active_table_id,
                    "is_joined": table_info.is_joined,
                },
                "field_values": field_values,
            }

        # 2. å°† Python å­—å…¸è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
        try:
            json_str = json.dumps(
                all_tables_data,
                ensure_ascii=ensure_ascii,  # æ”¯æŒä¸­æ–‡ï¼ˆFalse æ—¶ä¸­æ–‡ä¸è½¬ä¹‰ï¼‰
                indent=indent,  # æ ¼å¼åŒ–ç¼©è¿›ï¼Œæé«˜å¯è¯»æ€§
                default=str,  # å…œåº•å¤„ç†å‰©ä½™ä¸å¯åºåˆ—åŒ–å¯¹è±¡
            )
            return json_str
        except Exception as e:
            raise Exception(f"JSON åºåˆ—åŒ–å¤±è´¥ï¼š{str(e)}") from e


# å…¨å±€å®ä¾‹ - ä½¿ç”¨å¤šè¡¨ç®¡ç†å™¨
_loader: Optional[MultiExcelLoader] = None


def get_loader() -> MultiExcelLoader:
    """è·å–å…¨å±€ MultiExcelLoader å®ä¾‹"""
    global _loader
    if _loader is None:
        _loader = MultiExcelLoader()
    return _loader


def reset_loader() -> None:
    """é‡ç½®å…¨å±€ MultiExcelLoader å®ä¾‹"""
    global _loader
    _loader = MultiExcelLoader()
