import asyncio
import os
import sys
# å¼ºåˆ¶ç¦ç”¨æœ¬åœ°ä»£ç†ï¼Œè§£å†³ Ollama 502 é”™è¯¯
os.environ["NO_PROXY"] = "localhost,127.0.0.1"
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from langchain_core.messages import HumanMessage

from src.graph.graph import GraphWorkflow
from excel_agent.logger import setup_logging, get_logger
from sqlserver import get_schema_context, execute_sql_query
from excel_agent.business_metadata import resolve_table_names
from dotenv import load_dotenv

from langgraph.errors import GraphRecursionError

# é…ç½®æ—¥å¿—
setup_logging()
logger = get_logger("analysis_runner")


async def run_analysis():
    load_dotenv()

    # 1. å‡†å¤‡æŸ¥è¯¢
    query = "26è´¢å¹´ITçš„é¢„ç®—è´¹ç”¨å’Œ25è´¢å¹´å®é™…æ•°æ¯”ï¼Œå˜åŒ–æ˜¯ä»€ä¹ˆï¼Ÿ"
    logger.info(f"\nğŸ” ç”¨æˆ·é—®é¢˜: {query}")
    logger.info("-" * 50)

    # 2. æ‰“å° SQL Server è¡¨ç»“æ„æ‘˜è¦ï¼ˆç”¨äºç¡®è®¤è¿æ¥ï¼‰
    try:
        tables = resolve_table_names(query)
        schema_summary = get_schema_context(tables)
        logger.info("ğŸ“š SQL Server Schema Summary:\n" + schema_summary)
    except Exception as e:
        logger.error(f"âŒ SQL Server è¿æ¥å¤±è´¥: {e}")
        return

    # 3. å¯é€‰ï¼šæ‰§è¡Œä¸€ä¸ªç®€å•çš„è¿é€šæ€§æŸ¥è¯¢
    try:
        ping_df = execute_sql_query("SELECT 1 AS ok")
        logger.info(f"âœ… SQL Server è¿æ¥æˆåŠŸï¼Œæµ‹è¯•æŸ¥è¯¢ç»“æœ: {ping_df.to_dict(orient='records')}")
    except Exception as e:
        logger.error(f"âŒ SQL Server æµ‹è¯•æŸ¥è¯¢å¤±è´¥: {e}")
        return

    # 4. è¿è¡Œå·¥ä½œæµ
    workflow = GraphWorkflow()
    inputs = {"messages": [HumanMessage(content=query)]}

    logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
    try:
        async for event in workflow.get_graph().astream(inputs, config={"recursion_limit": 15}):
            for key, value in event.items():
                logger.info("-" * 50 + key + "-" * 50)
                if key == "analyze_intent":
                    if value.get("error_message"):
                        logger.error(
                            f" analyze_intent  æ‰§è¡Œé”™è¯¯: {value.get('error_message')}"
                        )
                    else:
                        logger.info(f"æ„å›¾åˆ†æ: {value.get('intent_analysis')}...")

                elif key == "generate_sql":
                    if value.get("retry_count", 0) > 0:
                        logger.info(f"   (é‡è¯•æ¬¡æ•°: {value.get('retry_count')})")
                    if value.get("error_message"):
                        logger.error(
                            f" generate_sql  æ‰§è¡Œé”™è¯¯: {value.get('error_message')}"
                        )
                    if value.get("sql_query"):
                        logger.info(f"   ç”Ÿæˆ SQL: {value.get('sql_query')}")

                elif key == "validate_sql":
                    valid = value.get("sql_valid")
                    if not valid:
                        logger.warning(
                            f" validate_sql  é”™è¯¯ä¿¡æ¯: {value.get('error_message')}"
                        )

                elif key == "execute_sql":
                    if value.get("error_message"):
                        logger.error(
                            f"  execute_sql æ‰§è¡Œé”™è¯¯: {value.get('error_message')}"
                        )
                    else:
                        logger.info("  execute_sql æ‰§è¡ŒæˆåŠŸ")

                elif key == "refine_answer":
                    messages = value.get("messages", [])
                    if messages:
                        logger.info(f"æœ€ç»ˆå›ç­”: {messages[0].content}")

    except GraphRecursionError:
        logger.error("âŒ é€’å½’æ¬¡æ•°è¿‡å¤šï¼Œå·¥ä½œæµåœæ­¢ã€‚")
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(run_analysis())
